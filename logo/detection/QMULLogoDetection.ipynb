{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QMULLogoDetection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUvZRzIIV8XJ",
        "colab_type": "code",
        "outputId": "f9fff1c1-d8cf-4cbb-f3fe-eb0c2a4c8abe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!pip install q numpy==1.17"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: q in /usr/local/lib/python3.6/dist-packages (2.6)\n",
            "Requirement already satisfied: numpy==1.17 in /usr/local/lib/python3.6/dist-packages (1.17.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duKFp0_xWB9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohweatISXQ7q",
        "colab_type": "code",
        "outputId": "f0466961-45bc-45a1-d3b9-55ebbd76c022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1p1BWofDJOKXqCtO0JPT5VyuIPOsuxOuj' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1p1BWofDJOKXqCtO0JPT5VyuIPOsuxOuj\" -O openlogo.tar && rm -rf /tmp/cookies.txt\n",
        "!tar -xvf openlogo.tar\n",
        "\n",
        "images_folder = \"openlogo/JPEGImages\"\n",
        "annotations_folder = \"openlogo/Annotations\"\n",
        "train_query_file = \"openlogo/ImageSets/Main/train_test/train_all.txt\"\n",
        "test_query_file = \"openlogo/ImageSets/Main/train_test/test_all.txt\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-30 12:20:47--  https://docs.google.com/uc?export=download&confirm=HgYf&id=1p1BWofDJOKXqCtO0JPT5VyuIPOsuxOuj\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.204.100, 74.125.204.138, 74.125.204.113, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.204.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-10-1g-docs.googleusercontent.com/docs/securesc/a2btu4luhvkr1efh6buklvi2vngqil2q/p6g872gqhi2df79hi5nbr15svtreil21/1590841200000/14735798989986763843/00602089151624592334Z/1p1BWofDJOKXqCtO0JPT5VyuIPOsuxOuj?e=download [following]\n",
            "--2020-05-30 12:20:47--  https://doc-10-1g-docs.googleusercontent.com/docs/securesc/a2btu4luhvkr1efh6buklvi2vngqil2q/p6g872gqhi2df79hi5nbr15svtreil21/1590841200000/14735798989986763843/00602089151624592334Z/1p1BWofDJOKXqCtO0JPT5VyuIPOsuxOuj?e=download\n",
            "Resolving doc-10-1g-docs.googleusercontent.com (doc-10-1g-docs.googleusercontent.com)... 74.125.203.132, 2404:6800:4008:c03::84\n",
            "Connecting to doc-10-1g-docs.googleusercontent.com (doc-10-1g-docs.googleusercontent.com)|74.125.203.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=mc8k4daapqubm&continue=https://doc-10-1g-docs.googleusercontent.com/docs/securesc/a2btu4luhvkr1efh6buklvi2vngqil2q/p6g872gqhi2df79hi5nbr15svtreil21/1590841200000/14735798989986763843/00602089151624592334Z/1p1BWofDJOKXqCtO0JPT5VyuIPOsuxOuj?e%3Ddownload&hash=ff1ibtc08l7bmfpe2o855d1b2frdgapb [following]\n",
            "--2020-05-30 12:20:47--  https://docs.google.com/nonceSigner?nonce=mc8k4daapqubm&continue=https://doc-10-1g-docs.googleusercontent.com/docs/securesc/a2btu4luhvkr1efh6buklvi2vngqil2q/p6g872gqhi2df79hi5nbr15svtreil21/1590841200000/14735798989986763843/00602089151624592334Z/1p1BWofDJOKXqCtO0JPT5VyuIPOsuxOuj?e%3Ddownload&hash=ff1ibtc08l7bmfpe2o855d1b2frdgapb\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.204.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-10-1g-docs.googleusercontent.com/docs/securesc/a2btu4luhvkr1efh6buklvi2vngqil2q/p6g872gqhi2df79hi5nbr15svtreil21/1590841200000/14735798989986763843/00602089151624592334Z/1p1BWofDJOKXqCtO0JPT5VyuIPOsuxOuj?e=download&nonce=mc8k4daapqubm&user=00602089151624592334Z&hash=ouv0si96bdu09uafk330ltauqb7u30p9 [following]\n",
            "--2020-05-30 12:20:47--  https://doc-10-1g-docs.googleusercontent.com/docs/securesc/a2btu4luhvkr1efh6buklvi2vngqil2q/p6g872gqhi2df79hi5nbr15svtreil21/1590841200000/14735798989986763843/00602089151624592334Z/1p1BWofDJOKXqCtO0JPT5VyuIPOsuxOuj?e=download&nonce=mc8k4daapqubm&user=00602089151624592334Z&hash=ouv0si96bdu09uafk330ltauqb7u30p9\n",
            "Connecting to doc-10-1g-docs.googleusercontent.com (doc-10-1g-docs.googleusercontent.com)|74.125.203.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-tar]\n",
            "Saving to: ‘openlogo.tar’\n",
            "\n",
            "openlogo.tar            [               <=>  ]   3.73G  40.5MB/s               "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mOms3QMWHUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%shell\n",
        "\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.3.0\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2rVDD-wWIr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Ejf17kWLkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_pattern = re.compile(r'^(?P<key>\\w+)\\.jpg$')\n",
        "annotation_pattern = re.compile(r'^(?P<key>\\w+)\\.xml$')\n",
        "\n",
        "class LogoDetectionDataset(Dataset):\n",
        "  \n",
        "  def __init__(self, image_folder, annotation_folder, query_file, transform=None, target_transform=None):\n",
        "    self.image_folder = image_folder\n",
        "    self.annotation_folder = annotation_folder\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "    self.image_names = self.__get_file_names__(image_folder, image_pattern)\n",
        "    self.annotation_names = self.__get_file_names__(annotation_folder, annotation_pattern)\n",
        "\n",
        "    self.keys = sorted(list(set(self.image_names.keys()) & set(self.annotation_names.keys())))\n",
        "    with open(query_file) as file:\n",
        "      file_content = file.read()\n",
        "      self.keys = list(filter(lambda key: key in file_content, self.keys))\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.keys)\n",
        "\n",
        "  def __getitem__(self, index): \n",
        "    key = self.keys[index]\n",
        "\n",
        "    image_name = self.image_names[key]\n",
        "    annotation_name = self.annotation_names[key]\n",
        "\n",
        "    image_path = os.path.join(self.image_folder, image_name)\n",
        "    annotation_path = os.path.join(self.annotation_folder, annotation_name)\n",
        "\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    target = self.__get_target__(annotation_path, index)\n",
        "\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "\n",
        "    if self.target_transform:\n",
        "      img, target = self.target_transform(img, target)\n",
        "\n",
        "    #img = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])(img)  \n",
        "\n",
        "    return img, target\n",
        "\n",
        "  def __get_target__(self, annotation_path, index):\n",
        "    target = {}\n",
        "    boxes = []\n",
        "    root = ET.parse(annotation_path).getroot()\n",
        "    for bndbox in root.findall('object/bndbox'):\n",
        "      xmin = int(bndbox[0].text)\n",
        "      ymin = int(bndbox[1].text)\n",
        "      xmax = int(bndbox[2].text)\n",
        "      ymax = int(bndbox[3].text)\n",
        "      boxes.append((xmin, ymin, xmax, ymax))\n",
        "\n",
        "    boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "    num_objs = len(boxes)\n",
        "    labels = torch.ones((num_objs), dtype=torch.int64)\n",
        "    img_id = torch.tensor([index])\n",
        "    area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "    iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "\n",
        "    target['boxes'] = boxes\n",
        "    target['labels'] = labels\n",
        "    target['image_id'] = img_id\n",
        "    target['area'] = area\n",
        "    target['iscrowd'] = iscrowd\n",
        "    return target\n",
        "\n",
        "  def __get_file_names__(self, folder, file_name_pattern):\n",
        "    file_names = {}\n",
        "    for f in listdir(folder):\n",
        "      match = file_name_pattern.match(f)\n",
        "      if not match:\n",
        "        continue\n",
        "      \n",
        "      num = match.group('key')\n",
        "      if num == '':\n",
        "        continue\n",
        "      \n",
        "      file_names[num] = f\n",
        "\n",
        "    return file_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlPUt2hSW-LF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import transforms as detectionTransforms\n",
        "\n",
        "trn = transforms.Compose([\n",
        "                          transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
        "                          transforms.RandomGrayscale(p=0.1)\n",
        "])\n",
        "\n",
        "target_trn = detectionTransforms.Compose([\n",
        "                                detectionTransforms.ToTensor(),\n",
        "                                detectionTransforms.RandomHorizontalFlip(0.5)\n",
        "])\n",
        "\n",
        "test_target_trn = detectionTransforms.Compose([\n",
        "                                detectionTransforms.ToTensor(),\n",
        "])\n",
        "\n",
        "num_classes = 2\n",
        "batch_size = 4\n",
        "\n",
        "dataset = LogoDetectionDataset(images_folder, annotations_folder, train_query_file, transform=trn, target_transform=target_trn)\n",
        "test_dataset = LogoDetectionDataset(images_folder, annotations_folder, test_query_file, target_transform=test_target_trn)\n",
        "orig_test_dataset = LogoDetectionDataset(images_folder, annotations_folder, test_query_file)\n",
        "\n",
        "validation_size = .0\n",
        "\n",
        "data_size = len(dataset)\n",
        "test_data_size = len(test_dataset)\n",
        "\n",
        "split_val = int(np.floor(validation_size * data_size))\n",
        "\n",
        "indices = list(range(data_size))\n",
        "test_indices = list(range(test_data_size))\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(indices)\n",
        "np.random.shuffle(test_indices)\n",
        "val_indices, train_indices = indices[:split_val], indices[split_val:]\n",
        "\n",
        "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n",
        "val_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_indices)\n",
        "test_sampler = torch.utils.data.sampler.SubsetRandomSampler(test_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
        "                                           sampler=train_sampler, collate_fn=utils.collate_fn)\n",
        "val_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
        "                                         sampler=val_sampler, collate_fn=utils.collate_fn)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1,\n",
        "                                          sampler=test_sampler, collate_fn=utils.collate_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4Bg9n8XXHNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "model.to(device)\n",
        "\n",
        "params = (p for p in model.parameters() if p.requires_grad)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.5, step_size=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl7bjH0yT-6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.load(\"drive/My Drive/save/save-aug-5\")\n",
        "model.to(device)\n",
        "\n",
        "params = (p for p in model.parameters() if p.requires_grad)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.00125, momentum=0.9, weight_decay=0.001)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.5, step_size=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wd51DG_tO9aP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = torch.load(\"drive/My Drive/save/save-aug-2-checkponit.pth\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "lr_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ7wvuN4XIrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "last_saved_epoch = 0\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  train_one_epoch(model, optimizer, train_loader, device, last_saved_epoch + epoch, print_freq=1000)\n",
        "  lr_scheduler.step()\n",
        "  torch.save({'model_state_dict': model.state_dict(),                                                 \n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': lr_scheduler.state_dict()}, \"drive/My Drive/save/save-aug-\" + str(last_saved_epoch + epoch) + \"-checkponit.pth\") \n",
        "  torch.save(model, \"drive/My Drive/save/save-aug-\" + str(last_saved_epoch + epoch))\n",
        "\n",
        "torch.save(model, \"drive/My Drive/save/save-aug-2-complete\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT2Y7HdxhPv1",
        "colab_type": "code",
        "outputId": "66c1dde3-d711-433e-c103-689afd37f7d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = torch.load(\"drive/My Drive/save/save-aug-complete\")\n",
        "evaluate(model, test_loader, device=device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero(Tensor input, *, Tensor out)\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(Tensor input, *, bool as_tuple)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test:  [   0/8322]  eta: 2:01:32  model_time: 0.8074 (0.8074)  evaluator_time: 0.0153 (0.0153)  time: 0.8763  data: 0.0450  max mem: 575\n",
            "Test:  [ 100/8322]  eta: 0:50:37  model_time: 0.3576 (0.3451)  evaluator_time: 0.0036 (0.0049)  time: 0.3746  data: 0.0159  max mem: 655\n",
            "Test:  [ 200/8322]  eta: 0:49:37  model_time: 0.3451 (0.3400)  evaluator_time: 0.0038 (0.0049)  time: 0.3810  data: 0.0372  max mem: 722\n",
            "Test:  [ 300/8322]  eta: 0:49:15  model_time: 0.3317 (0.3411)  evaluator_time: 0.0038 (0.0049)  time: 0.3617  data: 0.0189  max mem: 732\n",
            "Test:  [ 400/8322]  eta: 0:48:20  model_time: 0.3300 (0.3390)  evaluator_time: 0.0038 (0.0048)  time: 0.3492  data: 0.0163  max mem: 732\n",
            "Test:  [ 500/8322]  eta: 0:47:41  model_time: 0.3520 (0.3385)  evaluator_time: 0.0038 (0.0048)  time: 0.3633  data: 0.0170  max mem: 732\n",
            "Test:  [ 600/8322]  eta: 0:47:05  model_time: 0.3363 (0.3387)  evaluator_time: 0.0039 (0.0048)  time: 0.3666  data: 0.0193  max mem: 732\n",
            "Test:  [ 700/8322]  eta: 0:46:27  model_time: 0.3535 (0.3390)  evaluator_time: 0.0042 (0.0047)  time: 0.3653  data: 0.0157  max mem: 732\n",
            "Test:  [ 800/8322]  eta: 0:45:45  model_time: 0.3216 (0.3373)  evaluator_time: 0.0037 (0.0047)  time: 0.3727  data: 0.0517  max mem: 813\n",
            "Test:  [ 900/8322]  eta: 0:45:09  model_time: 0.3334 (0.3371)  evaluator_time: 0.0036 (0.0047)  time: 0.3626  data: 0.0217  max mem: 813\n",
            "Test:  [1000/8322]  eta: 0:44:30  model_time: 0.3350 (0.3371)  evaluator_time: 0.0036 (0.0047)  time: 0.3641  data: 0.0237  max mem: 813\n",
            "Test:  [1100/8322]  eta: 0:43:49  model_time: 0.3293 (0.3369)  evaluator_time: 0.0044 (0.0047)  time: 0.3601  data: 0.0206  max mem: 813\n",
            "Test:  [1200/8322]  eta: 0:43:15  model_time: 0.3456 (0.3371)  evaluator_time: 0.0041 (0.0047)  time: 0.3695  data: 0.0228  max mem: 813\n",
            "Test:  [1300/8322]  eta: 0:42:46  model_time: 0.3435 (0.3374)  evaluator_time: 0.0039 (0.0047)  time: 0.3630  data: 0.0233  max mem: 1440\n",
            "Test:  [1400/8322]  eta: 0:42:11  model_time: 0.3502 (0.3379)  evaluator_time: 0.0042 (0.0047)  time: 0.3690  data: 0.0205  max mem: 1440\n",
            "Test:  [1500/8322]  eta: 0:41:33  model_time: 0.3621 (0.3377)  evaluator_time: 0.0036 (0.0048)  time: 0.3743  data: 0.0171  max mem: 1440\n",
            "Test:  [1600/8322]  eta: 0:40:59  model_time: 0.3582 (0.3378)  evaluator_time: 0.0036 (0.0048)  time: 0.3667  data: 0.0165  max mem: 1440\n",
            "Test:  [1700/8322]  eta: 0:40:18  model_time: 0.3303 (0.3372)  evaluator_time: 0.0036 (0.0047)  time: 0.3507  data: 0.0172  max mem: 1440\n",
            "Test:  [1800/8322]  eta: 0:39:36  model_time: 0.3254 (0.3366)  evaluator_time: 0.0039 (0.0047)  time: 0.3513  data: 0.0225  max mem: 1440\n",
            "Test:  [1900/8322]  eta: 0:38:59  model_time: 0.3351 (0.3365)  evaluator_time: 0.0036 (0.0047)  time: 0.3571  data: 0.0166  max mem: 1440\n",
            "Test:  [2000/8322]  eta: 0:38:21  model_time: 0.3419 (0.3365)  evaluator_time: 0.0036 (0.0047)  time: 0.3684  data: 0.0198  max mem: 1440\n",
            "Test:  [2100/8322]  eta: 0:37:46  model_time: 0.3496 (0.3366)  evaluator_time: 0.0038 (0.0047)  time: 0.3704  data: 0.0214  max mem: 1440\n",
            "Test:  [2200/8322]  eta: 0:37:10  model_time: 0.3462 (0.3366)  evaluator_time: 0.0039 (0.0047)  time: 0.3588  data: 0.0174  max mem: 1440\n",
            "Test:  [2300/8322]  eta: 0:36:34  model_time: 0.3516 (0.3366)  evaluator_time: 0.0037 (0.0047)  time: 0.3694  data: 0.0227  max mem: 1440\n",
            "Test:  [2400/8322]  eta: 0:35:59  model_time: 0.3572 (0.3368)  evaluator_time: 0.0039 (0.0047)  time: 0.3736  data: 0.0172  max mem: 1440\n",
            "Test:  [2500/8322]  eta: 0:35:23  model_time: 0.3512 (0.3366)  evaluator_time: 0.0038 (0.0047)  time: 0.3636  data: 0.0175  max mem: 1440\n",
            "Test:  [2600/8322]  eta: 0:34:48  model_time: 0.3365 (0.3367)  evaluator_time: 0.0043 (0.0047)  time: 0.3542  data: 0.0210  max mem: 1440\n",
            "Test:  [2700/8322]  eta: 0:34:12  model_time: 0.3341 (0.3368)  evaluator_time: 0.0036 (0.0047)  time: 0.3581  data: 0.0195  max mem: 1440\n",
            "Test:  [2800/8322]  eta: 0:33:37  model_time: 0.3413 (0.3370)  evaluator_time: 0.0044 (0.0047)  time: 0.3729  data: 0.0283  max mem: 1440\n",
            "Test:  [2900/8322]  eta: 0:33:01  model_time: 0.3555 (0.3370)  evaluator_time: 0.0040 (0.0047)  time: 0.3690  data: 0.0222  max mem: 1440\n",
            "Test:  [3000/8322]  eta: 0:32:24  model_time: 0.3537 (0.3369)  evaluator_time: 0.0037 (0.0047)  time: 0.3685  data: 0.0191  max mem: 1440\n",
            "Test:  [3100/8322]  eta: 0:31:49  model_time: 0.3316 (0.3370)  evaluator_time: 0.0038 (0.0047)  time: 0.3695  data: 0.0276  max mem: 1440\n",
            "Test:  [3200/8322]  eta: 0:31:12  model_time: 0.3417 (0.3371)  evaluator_time: 0.0036 (0.0047)  time: 0.3691  data: 0.0226  max mem: 1440\n",
            "Test:  [3300/8322]  eta: 0:30:35  model_time: 0.3538 (0.3371)  evaluator_time: 0.0039 (0.0047)  time: 0.3703  data: 0.0206  max mem: 1440\n",
            "Test:  [3400/8322]  eta: 0:29:59  model_time: 0.3392 (0.3372)  evaluator_time: 0.0034 (0.0047)  time: 0.3641  data: 0.0210  max mem: 1440\n",
            "Test:  [3500/8322]  eta: 0:29:22  model_time: 0.3574 (0.3372)  evaluator_time: 0.0039 (0.0047)  time: 0.3708  data: 0.0163  max mem: 1440\n",
            "Test:  [3600/8322]  eta: 0:28:45  model_time: 0.3506 (0.3371)  evaluator_time: 0.0037 (0.0047)  time: 0.3614  data: 0.0327  max mem: 1440\n",
            "Test:  [3700/8322]  eta: 0:28:09  model_time: 0.3359 (0.3370)  evaluator_time: 0.0037 (0.0047)  time: 0.3514  data: 0.0157  max mem: 1440\n",
            "Test:  [3800/8322]  eta: 0:27:33  model_time: 0.3509 (0.3372)  evaluator_time: 0.0037 (0.0047)  time: 0.3626  data: 0.0171  max mem: 1440\n",
            "Test:  [3900/8322]  eta: 0:26:56  model_time: 0.3423 (0.3372)  evaluator_time: 0.0038 (0.0046)  time: 0.3610  data: 0.0240  max mem: 1440\n",
            "Test:  [4000/8322]  eta: 0:26:18  model_time: 0.3404 (0.3371)  evaluator_time: 0.0042 (0.0046)  time: 0.3526  data: 0.0141  max mem: 1440\n",
            "Test:  [4100/8322]  eta: 0:25:42  model_time: 0.3468 (0.3372)  evaluator_time: 0.0035 (0.0047)  time: 0.3546  data: 0.0187  max mem: 1440\n",
            "Test:  [4200/8322]  eta: 0:25:05  model_time: 0.3336 (0.3371)  evaluator_time: 0.0034 (0.0047)  time: 0.3524  data: 0.0160  max mem: 1440\n",
            "Test:  [4300/8322]  eta: 0:24:29  model_time: 0.3498 (0.3371)  evaluator_time: 0.0037 (0.0047)  time: 0.3596  data: 0.0189  max mem: 1440\n",
            "Test:  [4400/8322]  eta: 0:23:54  model_time: 0.3381 (0.3372)  evaluator_time: 0.0039 (0.0047)  time: 0.4097  data: 0.0541  max mem: 1440\n",
            "Test:  [4500/8322]  eta: 0:23:17  model_time: 0.3334 (0.3372)  evaluator_time: 0.0039 (0.0046)  time: 0.3599  data: 0.0172  max mem: 1440\n",
            "Test:  [4600/8322]  eta: 0:22:40  model_time: 0.3462 (0.3370)  evaluator_time: 0.0039 (0.0046)  time: 0.3821  data: 0.0325  max mem: 1440\n",
            "Test:  [4700/8322]  eta: 0:22:03  model_time: 0.3510 (0.3370)  evaluator_time: 0.0037 (0.0046)  time: 0.3718  data: 0.0170  max mem: 1440\n",
            "Test:  [4800/8322]  eta: 0:21:26  model_time: 0.3477 (0.3369)  evaluator_time: 0.0040 (0.0047)  time: 0.3634  data: 0.0178  max mem: 1440\n",
            "Test:  [4900/8322]  eta: 0:20:49  model_time: 0.3373 (0.3368)  evaluator_time: 0.0040 (0.0047)  time: 0.3550  data: 0.0185  max mem: 1440\n",
            "Test:  [5000/8322]  eta: 0:20:13  model_time: 0.3362 (0.3367)  evaluator_time: 0.0039 (0.0047)  time: 0.4014  data: 0.0547  max mem: 1440\n",
            "Test:  [5100/8322]  eta: 0:19:36  model_time: 0.3458 (0.3367)  evaluator_time: 0.0038 (0.0047)  time: 0.3749  data: 0.0258  max mem: 1440\n",
            "Test:  [5200/8322]  eta: 0:19:00  model_time: 0.3344 (0.3365)  evaluator_time: 0.0036 (0.0047)  time: 0.3590  data: 0.0234  max mem: 1440\n",
            "Test:  [5300/8322]  eta: 0:18:24  model_time: 0.3326 (0.3366)  evaluator_time: 0.0041 (0.0047)  time: 0.3644  data: 0.0176  max mem: 1440\n",
            "Test:  [5400/8322]  eta: 0:17:47  model_time: 0.3516 (0.3365)  evaluator_time: 0.0039 (0.0047)  time: 0.3701  data: 0.0267  max mem: 1440\n",
            "Test:  [5500/8322]  eta: 0:17:10  model_time: 0.3298 (0.3364)  evaluator_time: 0.0037 (0.0047)  time: 0.3612  data: 0.0225  max mem: 1440\n",
            "Test:  [5600/8322]  eta: 0:16:34  model_time: 0.3298 (0.3364)  evaluator_time: 0.0037 (0.0047)  time: 0.3608  data: 0.0182  max mem: 1440\n",
            "Test:  [5700/8322]  eta: 0:15:57  model_time: 0.3361 (0.3364)  evaluator_time: 0.0036 (0.0047)  time: 0.3715  data: 0.0252  max mem: 1440\n",
            "Test:  [5800/8322]  eta: 0:15:21  model_time: 0.3238 (0.3364)  evaluator_time: 0.0038 (0.0047)  time: 0.3464  data: 0.0223  max mem: 1440\n",
            "Test:  [5900/8322]  eta: 0:14:44  model_time: 0.3397 (0.3364)  evaluator_time: 0.0033 (0.0047)  time: 0.3659  data: 0.0199  max mem: 1440\n",
            "Test:  [6000/8322]  eta: 0:14:07  model_time: 0.3332 (0.3364)  evaluator_time: 0.0040 (0.0047)  time: 0.3542  data: 0.0167  max mem: 1440\n",
            "Test:  [6100/8322]  eta: 0:13:31  model_time: 0.3338 (0.3365)  evaluator_time: 0.0032 (0.0047)  time: 0.3553  data: 0.0146  max mem: 1440\n",
            "Test:  [6200/8322]  eta: 0:12:55  model_time: 0.3383 (0.3365)  evaluator_time: 0.0039 (0.0047)  time: 0.3652  data: 0.0261  max mem: 1440\n",
            "Test:  [6300/8322]  eta: 0:12:18  model_time: 0.3287 (0.3364)  evaluator_time: 0.0036 (0.0047)  time: 0.3470  data: 0.0151  max mem: 1440\n",
            "Test:  [6400/8322]  eta: 0:11:41  model_time: 0.3346 (0.3364)  evaluator_time: 0.0038 (0.0047)  time: 0.3596  data: 0.0224  max mem: 1440\n",
            "Test:  [6500/8322]  eta: 0:11:05  model_time: 0.3484 (0.3365)  evaluator_time: 0.0038 (0.0047)  time: 0.3718  data: 0.0209  max mem: 1440\n",
            "Test:  [6600/8322]  eta: 0:10:28  model_time: 0.3348 (0.3365)  evaluator_time: 0.0035 (0.0047)  time: 0.3803  data: 0.0280  max mem: 1440\n",
            "Test:  [6700/8322]  eta: 0:09:52  model_time: 0.3356 (0.3365)  evaluator_time: 0.0034 (0.0047)  time: 0.3582  data: 0.0180  max mem: 1440\n",
            "Test:  [6800/8322]  eta: 0:09:15  model_time: 0.3398 (0.3364)  evaluator_time: 0.0036 (0.0047)  time: 0.3692  data: 0.0317  max mem: 1440\n",
            "Test:  [6900/8322]  eta: 0:08:39  model_time: 0.3336 (0.3364)  evaluator_time: 0.0034 (0.0047)  time: 0.3551  data: 0.0202  max mem: 1440\n",
            "Test:  [7000/8322]  eta: 0:08:02  model_time: 0.3583 (0.3364)  evaluator_time: 0.0036 (0.0047)  time: 0.3638  data: 0.0179  max mem: 1440\n",
            "Test:  [7100/8322]  eta: 0:07:26  model_time: 0.3352 (0.3365)  evaluator_time: 0.0037 (0.0047)  time: 0.3531  data: 0.0186  max mem: 1440\n",
            "Test:  [7200/8322]  eta: 0:06:49  model_time: 0.3476 (0.3365)  evaluator_time: 0.0035 (0.0047)  time: 0.3501  data: 0.0150  max mem: 1440\n",
            "Test:  [7300/8322]  eta: 0:06:13  model_time: 0.3312 (0.3365)  evaluator_time: 0.0039 (0.0047)  time: 0.3586  data: 0.0200  max mem: 1440\n",
            "Test:  [7400/8322]  eta: 0:05:36  model_time: 0.3480 (0.3365)  evaluator_time: 0.0037 (0.0047)  time: 0.3611  data: 0.0283  max mem: 1440\n",
            "Test:  [7500/8322]  eta: 0:05:00  model_time: 0.3489 (0.3365)  evaluator_time: 0.0038 (0.0046)  time: 0.3772  data: 0.0344  max mem: 1440\n",
            "Test:  [7600/8322]  eta: 0:04:23  model_time: 0.3575 (0.3365)  evaluator_time: 0.0037 (0.0046)  time: 0.3847  data: 0.0330  max mem: 1440\n",
            "Test:  [7700/8322]  eta: 0:03:47  model_time: 0.3277 (0.3364)  evaluator_time: 0.0037 (0.0046)  time: 0.3563  data: 0.0298  max mem: 1440\n",
            "Test:  [7800/8322]  eta: 0:03:10  model_time: 0.3429 (0.3363)  evaluator_time: 0.0037 (0.0046)  time: 0.3837  data: 0.0406  max mem: 1440\n",
            "Test:  [7900/8322]  eta: 0:02:34  model_time: 0.3348 (0.3363)  evaluator_time: 0.0033 (0.0046)  time: 0.3644  data: 0.0142  max mem: 1440\n",
            "Test:  [8000/8322]  eta: 0:01:57  model_time: 0.3266 (0.3364)  evaluator_time: 0.0035 (0.0046)  time: 0.3505  data: 0.0178  max mem: 1440\n",
            "Test:  [8100/8322]  eta: 0:01:21  model_time: 0.3434 (0.3364)  evaluator_time: 0.0037 (0.0046)  time: 0.3598  data: 0.0176  max mem: 1440\n",
            "Test:  [8200/8322]  eta: 0:00:44  model_time: 0.3238 (0.3363)  evaluator_time: 0.0034 (0.0046)  time: 0.3325  data: 0.0184  max mem: 1440\n",
            "Test:  [8300/8322]  eta: 0:00:08  model_time: 0.3540 (0.3364)  evaluator_time: 0.0039 (0.0046)  time: 0.3845  data: 0.0311  max mem: 1440\n",
            "Test:  [8321/8322]  eta: 0:00:00  model_time: 0.3471 (0.3364)  evaluator_time: 0.0037 (0.0046)  time: 0.3594  data: 0.0173  max mem: 1440\n",
            "Test: Total time: 0:50:37 (0.3650 s / it)\n",
            "Averaged stats: model_time: 0.3471 (0.3364)  evaluator_time: 0.0037 (0.0046)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=2.86s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.512\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.331\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.416\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.240\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.496\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.545\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.401\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.563\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.632\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<coco_eval.CocoEvaluator at 0x7f59492fafd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8NvPFB93a7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_iou(bb1, bb2):\n",
        "  bb1_x1 = int(bb1[0])\n",
        "  bb1_y1 = int(bb1[1])\n",
        "  bb1_x2 = int(bb1[2])\n",
        "  bb1_y2 = int(bb1[3])\n",
        "  bb2_x1 = int(bb2[0])\n",
        "  bb2_y1 = int(bb2[1])\n",
        "  bb2_x2 = int(bb2[2])\n",
        "  bb2_y2 = int(bb2[3])\n",
        "  assert bb1_x1 < bb1_x2\n",
        "  assert bb1_y1 < bb1_y2\n",
        "  assert bb2_x1 < bb2_x2\n",
        "  assert bb2_y1 < bb2_y2\n",
        "\n",
        "  x_left = max(bb1_x1, bb2_x1)\n",
        "  y_top = max(bb1_y1, bb2_y1)\n",
        "  x_right = min(bb1_x2, bb2_x2)\n",
        "  y_bottom = min(bb1_y2, bb2_y2)\n",
        "\n",
        "  display(str(x_left) + \" \" + str(y_top) + \" \" + str(x_right) + \" \" + str(y_bottom))\n",
        "\n",
        "  if x_right < x_left or y_bottom < y_top:\n",
        "    return 0.0\n",
        "\n",
        "  intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
        "\n",
        "  bb1_area = (bb1_x2 - bb1_x1) * (bb1_y2 - bb1_y1)\n",
        "  bb2_area = (bb2_x2 - bb2_x1) * (bb2_y2 - bb2_y1)\n",
        "\n",
        "  iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
        "  assert iou >= 0.0\n",
        "  assert iou <= 1.0\n",
        "  return iou"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}