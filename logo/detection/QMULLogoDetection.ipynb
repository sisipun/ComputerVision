{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QMULLogoDetection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUvZRzIIV8XJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install q numpy==1.17"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duKFp0_xWB9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohweatISXQ7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1p1BWofDJOKXqCtO0JPT5VyuIPOsuxOuj' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1p1BWofDJOKXqCtO0JPT5VyuIPOsuxOuj\" -O openlogo.tar && rm -rf /tmp/cookies.txt\n",
        "!tar -xvf openlogo.tar\n",
        "\n",
        "images_folder = \"openlogo/JPEGImages\"\n",
        "annotations_folder = \"openlogo/Annotations\"\n",
        "train_query_file = \"openlogo/ImageSets/Main/train_test/train_all.txt\"\n",
        "test_query_file = \"openlogo/ImageSets/Main/train_test/test_all.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mOms3QMWHUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%shell\n",
        "\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.3.0\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2rVDD-wWIr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Ejf17kWLkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_pattern = re.compile(r'^(?P<key>\\w+)\\.jpg$')\n",
        "annotation_pattern = re.compile(r'^(?P<key>\\w+)\\.xml$')\n",
        "\n",
        "class LogoDetectionDataset(Dataset):\n",
        "  \n",
        "  def __init__(self, image_folder, annotation_folder, query_file, transform=None, target_transform=None):\n",
        "    self.image_folder = image_folder\n",
        "    self.annotation_folder = annotation_folder\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "    self.image_names = self.__get_file_names__(image_folder, image_pattern)\n",
        "    self.annotation_names = self.__get_file_names__(annotation_folder, annotation_pattern)\n",
        "\n",
        "    self.keys = sorted(list(set(self.image_names.keys()) & set(self.annotation_names.keys())))\n",
        "    with open(query_file) as file:\n",
        "      file_content = file.read()\n",
        "      self.keys = list(filter(lambda key: key in file_content, self.keys))\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.keys)\n",
        "\n",
        "  def __getitem__(self, index): \n",
        "    key = self.keys[index]\n",
        "\n",
        "    image_name = self.image_names[key]\n",
        "    annotation_name = self.annotation_names[key]\n",
        "\n",
        "    image_path = os.path.join(self.image_folder, image_name)\n",
        "    annotation_path = os.path.join(self.annotation_folder, annotation_name)\n",
        "\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    target = self.__get_target__(annotation_path, index)\n",
        "\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "\n",
        "    if self.target_transform:\n",
        "      img, target = self.target_transform(img, target)\n",
        "\n",
        "    #img = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])(img)  \n",
        "\n",
        "    return img, target\n",
        "\n",
        "  def __get_target__(self, annotation_path, index):\n",
        "    target = {}\n",
        "    boxes = []\n",
        "    root = ET.parse(annotation_path).getroot()\n",
        "    for bndbox in root.findall('object/bndbox'):\n",
        "      xmin = int(bndbox[0].text)\n",
        "      ymin = int(bndbox[1].text)\n",
        "      xmax = int(bndbox[2].text)\n",
        "      ymax = int(bndbox[3].text)\n",
        "      boxes.append((xmin, ymin, xmax, ymax))\n",
        "\n",
        "    boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "    num_objs = len(boxes)\n",
        "    labels = torch.ones((num_objs), dtype=torch.int64)\n",
        "    img_id = torch.tensor([index])\n",
        "    area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "    iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "\n",
        "    target['boxes'] = boxes\n",
        "    target['labels'] = labels\n",
        "    target['image_id'] = img_id\n",
        "    target['area'] = area\n",
        "    target['iscrowd'] = iscrowd\n",
        "    return target\n",
        "\n",
        "  def __get_file_names__(self, folder, file_name_pattern):\n",
        "    file_names = {}\n",
        "    for f in listdir(folder):\n",
        "      match = file_name_pattern.match(f)\n",
        "      if not match:\n",
        "        continue\n",
        "      \n",
        "      num = match.group('key')\n",
        "      if num == '':\n",
        "        continue\n",
        "      \n",
        "      file_names[num] = f\n",
        "\n",
        "    return file_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlPUt2hSW-LF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import transforms as detectionTransforms\n",
        "\n",
        "trn = transforms.Compose([\n",
        "                          transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
        "                          transforms.RandomGrayscale(p=0.1)\n",
        "])\n",
        "\n",
        "target_trn = detectionTransforms.Compose([\n",
        "                                detectionTransforms.ToTensor(),\n",
        "                                detectionTransforms.RandomHorizontalFlip(0.5)\n",
        "])\n",
        "\n",
        "test_target_trn = detectionTransforms.Compose([\n",
        "                                detectionTransforms.ToTensor(),\n",
        "])\n",
        "\n",
        "num_classes = 2\n",
        "batch_size = 4\n",
        "\n",
        "dataset = LogoDetectionDataset(images_folder, annotations_folder, train_query_file, transform=trn, target_transform=target_trn)\n",
        "test_dataset = LogoDetectionDataset(images_folder, annotations_folder, test_query_file, target_transform=test_target_trn)\n",
        "orig_test_dataset = LogoDetectionDataset(images_folder, annotations_folder, test_query_file)\n",
        "\n",
        "validation_size = .0\n",
        "\n",
        "data_size = len(dataset)\n",
        "test_data_size = len(test_dataset)\n",
        "\n",
        "split_val = int(np.floor(validation_size * data_size))\n",
        "\n",
        "indices = list(range(data_size))\n",
        "test_indices = list(range(test_data_size))\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(indices)\n",
        "np.random.shuffle(test_indices)\n",
        "val_indices, train_indices = indices[:split_val], indices[split_val:]\n",
        "\n",
        "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n",
        "val_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_indices)\n",
        "test_sampler = torch.utils.data.sampler.SubsetRandomSampler(test_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
        "                                           sampler=train_sampler, collate_fn=utils.collate_fn)\n",
        "val_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
        "                                         sampler=val_sampler, collate_fn=utils.collate_fn)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1,\n",
        "                                          sampler=test_sampler, collate_fn=utils.collate_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4Bg9n8XXHNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "model.to(device)\n",
        "\n",
        "params = (p for p in model.parameters() if p.requires_grad)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.001)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.5, step_size=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl7bjH0yT-6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.load(\"ddrive/My Drive/save/save-aug-1\")\n",
        "model.to(device)\n",
        "\n",
        "params = (p for p in model.parameters() if p.requires_grad)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.001)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.1, step_size=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ7wvuN4XIrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "last_saved_epoch = 2\n",
        "num_epochs = 9\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  train_one_epoch(model, optimizer, train_loader, device, last_saved_epoch + epoch, print_freq=1000)\n",
        "  torch.save(model, \"drive/My Drive/save/save-aug-\" + str(last_saved_epoch + epoch))\n",
        "  lr_scheduler.step()\n",
        "  \n",
        "torch.save(model, \"drive/My Drive/save/save-aug-complete\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT2Y7HdxhPv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.load(\"drive/My Drive/save/save-aug-complete\")\n",
        "evaluate(model, test_loader, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8NvPFB93a7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_iou(bb1, bb2):\n",
        "  bb1_x1 = int(bb1[0])\n",
        "  bb1_y1 = int(bb1[1])\n",
        "  bb1_x2 = int(bb1[2])\n",
        "  bb1_y2 = int(bb1[3])\n",
        "  bb2_x1 = int(bb2[0])\n",
        "  bb2_y1 = int(bb2[1])\n",
        "  bb2_x2 = int(bb2[2])\n",
        "  bb2_y2 = int(bb2[3])\n",
        "  assert bb1_x1 < bb1_x2\n",
        "  assert bb1_y1 < bb1_y2\n",
        "  assert bb2_x1 < bb2_x2\n",
        "  assert bb2_y1 < bb2_y2\n",
        "\n",
        "  x_left = max(bb1_x1, bb2_x1)\n",
        "  y_top = max(bb1_y1, bb2_y1)\n",
        "  x_right = min(bb1_x2, bb2_x2)\n",
        "  y_bottom = min(bb1_y2, bb2_y2)\n",
        "\n",
        "  display(str(x_left) + \" \" + str(y_top) + \" \" + str(x_right) + \" \" + str(y_bottom))\n",
        "\n",
        "  if x_right < x_left or y_bottom < y_top:\n",
        "    return 0.0\n",
        "\n",
        "  intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
        "\n",
        "  bb1_area = (bb1_x2 - bb1_x1) * (bb1_y2 - bb1_y1)\n",
        "  bb2_area = (bb2_x2 - bb2_x1) * (bb2_y2 - bb2_y1)\n",
        "\n",
        "  iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
        "  assert iou >= 0.0\n",
        "  assert iou <= 1.0\n",
        "  return iou"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}